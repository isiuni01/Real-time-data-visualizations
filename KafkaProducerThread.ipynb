{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (invia_messaggi_a_kafka):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/isaia/.pyenv/versions/3.10.14/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/isaia/.pyenv/versions/3.10.14/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Users/isaia/.pyenv/versions/3.10.14/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/hb/dw89xtb95cl_b0blt4q7vzsr0000gn/T/ipykernel_3826/1798403710.py\", line 31, in invia_messaggi_a_kafka\n",
      "Exception in thread Thread-7 (invia_messaggi_a_kafka):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/isaia/.pyenv/versions/3.10.14/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "  File \"/Users/isaia/.pyenv/versions/3.10.14/lib/python3.10/site-packages/pykafka/producer.py\", line 411, in produce\n",
      "    self.run()\n",
      "  File \"/Users/isaia/.pyenv/versions/3.10.14/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Users/isaia/.pyenv/versions/3.10.14/lib/python3.10/threading.py\", line 953, in run\n",
      "    raise ProduceFailureError(\"Delivery report not received after timeout\")\n",
      "pykafka.exceptions.ProduceFailureError: Delivery report not received after timeout\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/hb/dw89xtb95cl_b0blt4q7vzsr0000gn/T/ipykernel_3826/1798403710.py\", line 31, in invia_messaggi_a_kafka\n",
      "  File \"/Users/isaia/.pyenv/versions/3.10.14/lib/python3.10/site-packages/pykafka/producer.py\", line 411, in produce\n",
      "    raise ProduceFailureError(\"Delivery report not received after timeout\")\n",
      "pykafka.exceptions.ProduceFailureError: Delivery report not received after timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutti i file sono stati processati.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pykafka import KafkaClient\n",
    "import json\n",
    "from time import sleep\n",
    "import threading\n",
    "from datetime import datetime\n",
    "\n",
    "# Configura Kafka\n",
    "KAFKA_BROKER = \"localhost:9091\"  # Sostituisci con il tuo broker Kafka\n",
    "client = KafkaClient(hosts=KAFKA_BROKER)\n",
    "\n",
    "# Specifica l'intervallo di righe da leggere\n",
    "START_ROW = 1  # Riga iniziale (0-indicizzata)\n",
    "END_ROW = 620402   # Riga finale esclusa (0-indicizzata)\n",
    "\n",
    "# Connettiti al broker Kafka\n",
    "def invia_messaggi_a_kafka(file_path, start_row, end_row, topic_name):\n",
    "    \"\"\"\n",
    "    Funzione per leggere un file CSV e inviare un intervallo di righe a Kafka.\n",
    "    \"\"\"\n",
    "    topic = client.topics[topic_name]   \n",
    "    producer = topic.get_sync_producer()\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for i, row in enumerate(reader):\n",
    "            if start_row <= i < end_row:\n",
    "                # Aggiorna il campo 'time' con il tempo corrente nel formato richiesto\n",
    "                row['time'] = datetime.now().strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'\n",
    "                \n",
    "                messaggio = json.dumps(row).encode('utf-8')\n",
    "                producer.produce(messaggio)\n",
    "                sleep(0.049)\n",
    "\n",
    "\n",
    "\n",
    "# Elenco dei file CSV\n",
    "file_paths = [\n",
    "    \"orderedData/ITA.csv\",\"orderedData/USA.csv\"\n",
    "]\n",
    "topics = [\"ITA\",\"USA\"]\n",
    "\n",
    "# Crea e avvia i thread\n",
    "threads = []\n",
    "for file_path, topic in zip(file_paths, topics):\n",
    "\n",
    "    thread = threading.Thread(target=invia_messaggi_a_kafka, \n",
    "        args=(file_path, START_ROW, END_ROW, \"boat_data\"))\n",
    "\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# Aspetta che tutti i thread terminino\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(\"Tutti i file sono stati processati.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in orderedData/GBR.csv: 1362997\n"
     ]
    }
   ],
   "source": [
    "file_path = \"orderedData/GBR.csv\"\n",
    "with open(file_path, 'r') as f:\n",
    "    row_count = sum(1 for _ in f) - 1  # subtract 1 for header\n",
    "print(f\"Number of rows in {file_path}: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valori diversi nella colonna 'foiling': {'', 'up5', 'up3', 'up4', 'down1', 'down4', 'up1', 'up2', 'down3', 'postrace', 'prestart', 'down2'}\n",
      "Numero di valori diversi: 12\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    foiling_values = set()\n",
    "    for row in reader:\n",
    "        foiling_values.add(row.get('leg'))\n",
    "print(f\"Valori diversi nella colonna 'foiling': {foiling_values}\")\n",
    "print(f\"Numero di valori diversi: {len(foiling_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invia_messaggi_a_kafka(file_path, start_row, end_row, topic_name):\n",
    "    \"\"\"\n",
    "    Funzione per leggere un file CSV e inviare un intervallo di righe a Kafka.\n",
    "    \"\"\"\n",
    "    topic = client.topics[topic_name]   \n",
    "    # Configura il produttore Kafka\n",
    "    producer = topic.get_sync_producer()\n",
    "\n",
    "    # Leggi il file CSV e invia l'intervallo di righe\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.DictReader(file)  # Legge il file CSV come dizionari\n",
    "        for i, row in enumerate(reader):\n",
    "            if start_row <= i < end_row:\n",
    "                messaggio = json.dumps(row).encode('utf-8')  # Serializza la riga in formato JSON\n",
    "                producer.produce(messaggio)  # Invia il messaggio a Kafka\n",
    "                sleep(0.05)\n",
    "                #print(f\"[{file_path}] Inviato: {messaggio}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
